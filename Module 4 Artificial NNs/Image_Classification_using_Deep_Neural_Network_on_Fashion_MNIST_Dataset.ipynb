{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNljA9W5JiBr"
      },
      "source": [
        "# Image Classification using Deep Neural Network on Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6iuyas9JiBu"
      },
      "outputs": [],
      "source": [
        "from keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmX90e3sJiBv"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
        "test = pd.read_csv(\"fashion-mnist_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Z8S-lnJiBw"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXiGKA-OJiBx"
      },
      "outputs": [],
      "source": [
        "output_mapping = { 0: \"T-shirt/Top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\",\n",
        "                 8: \"Bag\", 9: \"Ankle Boot\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wNGgXG6JiBx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train.iloc[i, 1:].values.reshape(28,28))\n",
        "    plt.xlabel(output_mapping[train.iloc[i, 0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-IyP10BJiBx"
      },
      "outputs": [],
      "source": [
        "train_image = np.array(train.iloc[:,1:])\n",
        "train_image = train_image/255\n",
        "train_label = np.array(train.iloc[:, 0])\n",
        "test_image = np.array(test.iloc[:,1:])\n",
        "test_image = test_image/255\n",
        "test_label = np.array(test.iloc[:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0W_dSmkJiBy"
      },
      "source": [
        "## Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWcjvx05JiBy"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(784,activation='relu'))\n",
        "model.add(layers.Dense(400,activation='relu'))\n",
        "model.add(layers.Dense(300,activation='relu'))\n",
        "model.add(layers.Dense(200,activation='relu'))\n",
        "model.add(layers.Dense(100,activation=\"relu\"))\n",
        "model.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhW5GpOLJiBz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVdkn_vtJiBz",
        "outputId": "fbaf181e-9770-4b92-f94a-8a8970bf8c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.5064 - accuracy: 0.8177 - val_loss: 0.4118 - val_accuracy: 0.8544\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3869 - accuracy: 0.8597 - val_loss: 0.3844 - val_accuracy: 0.8554\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.3486 - accuracy: 0.8730 - val_loss: 0.3532 - val_accuracy: 0.8632\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.3213 - accuracy: 0.8826 - val_loss: 0.3519 - val_accuracy: 0.8684\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.3055 - accuracy: 0.8882 - val_loss: 0.3340 - val_accuracy: 0.8806\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.2909 - accuracy: 0.8927 - val_loss: 0.3186 - val_accuracy: 0.8866\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.2764 - accuracy: 0.8988 - val_loss: 0.3719 - val_accuracy: 0.8696\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2658 - accuracy: 0.9016 - val_loss: 0.3293 - val_accuracy: 0.8872\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2564 - accuracy: 0.9066 - val_loss: 0.3410 - val_accuracy: 0.8850\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2481 - accuracy: 0.9087 - val_loss: 0.3419 - val_accuracy: 0.8870\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2353 - accuracy: 0.9128 - val_loss: 0.3465 - val_accuracy: 0.8842\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.2279 - accuracy: 0.9148 - val_loss: 0.3093 - val_accuracy: 0.8884\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.2224 - accuracy: 0.9175 - val_loss: 0.3205 - val_accuracy: 0.8915\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.2914 - val_accuracy: 0.8993\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.2121 - accuracy: 0.9206 - val_loss: 0.3337 - val_accuracy: 0.8891\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.2063 - accuracy: 0.9234 - val_loss: 0.3091 - val_accuracy: 0.8960\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1976 - accuracy: 0.9266 - val_loss: 0.3440 - val_accuracy: 0.8968\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1954 - accuracy: 0.9265 - val_loss: 0.3363 - val_accuracy: 0.8997\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1900 - accuracy: 0.9295 - val_loss: 0.3308 - val_accuracy: 0.8948\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.1862 - accuracy: 0.9295 - val_loss: 0.3783 - val_accuracy: 0.8979\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.1842 - accuracy: 0.9318 - val_loss: 0.3453 - val_accuracy: 0.8979\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.1782 - accuracy: 0.9335 - val_loss: 0.3504 - val_accuracy: 0.9011\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1743 - accuracy: 0.9343 - val_loss: 0.3725 - val_accuracy: 0.8929\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1681 - accuracy: 0.9368 - val_loss: 0.4206 - val_accuracy: 0.8965\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.1720 - accuracy: 0.9377 - val_loss: 0.3789 - val_accuracy: 0.8958\n",
            "Epoch 26/30\n",
            "1753/1875 [===========================>..] - ETA: 2s - loss: 0.1639 - accuracy: 0.9381"
          ]
        }
      ],
      "source": [
        "model.fit(train_image, train_label, epochs = 30, batch_size=32, validation_data=(test_image, test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzTt8xgjJiBz"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsu9zBpPJiBz"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_image, test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf5s26_gJiBz"
      },
      "outputs": [],
      "source": [
        "def visualize_pred(image, pred_prob, actual_label):\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(4,8), ncols=2)\n",
        "    ax1.imshow(image.reshape(28, 28).squeeze())\n",
        "    ax1.axis('off')\n",
        "    pred_label = np.argmax(pred_prob)\n",
        "    ax1.set_title([output_mapping[actual_label], output_mapping[pred_label]])\n",
        "    ax2.barh(np.arange(10), pred_prob)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Prediction Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aNN2HxAJiB0"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    visualize_pred(test_image[i],predictions[i],test_label[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKMnsTKZJiB0"
      },
      "source": [
        "## Deep Neural Network with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWQcRudjJiB0"
      },
      "outputs": [],
      "source": [
        "modelwithdropout = models.Sequential()\n",
        "modelwithdropout.add(layers.Flatten())\n",
        "modelwithdropout.add(layers.Dropout(0.25))\n",
        "modelwithdropout.add(layers.Dense(784,activation='relu'))\n",
        "modelwithdropout.add(layers.Dropout(0.25))\n",
        "modelwithdropout.add(layers.Dense(400,activation='relu'))\n",
        "modelwithdropout.add(layers.Dropout(0.25))\n",
        "modelwithdropout.add(layers.Dense(300,activation='relu'))\n",
        "modelwithdropout.add(layers.Dropout(0.25))\n",
        "modelwithdropout.add(layers.Dense(200,activation='relu'))\n",
        "modelwithdropout.add(layers.Dropout(0.25))\n",
        "modelwithdropout.add(layers.Dense(100,activation=\"relu\"))\n",
        "modelwithdropout.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyxZKSEgJiB0"
      },
      "outputs": [],
      "source": [
        "modelwithdropout.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EE6Z3dnJiB0"
      },
      "outputs": [],
      "source": [
        "modelwithdropout.fit(train_image, train_label, epochs = 30, batch_size=32, validation_data=(test_image, test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9qOBAkhJiB0"
      },
      "outputs": [],
      "source": [
        "predictionswithdropout = modelwithdropout.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYyccqetJiB0"
      },
      "outputs": [],
      "source": [
        "modelwithdropout.evaluate(test_image, test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7qWGo1oJiB1"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    visualize_pred(test_image[i],predictionswithdropout[i],test_label[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCinez44JiB1"
      },
      "source": [
        "## Does Deep Neural Network use Visual Information? What happens if we permute the pixel randomly for all images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBfA696bJiB1"
      },
      "outputs": [],
      "source": [
        "permutation = torch.randperm(784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8ezmTf3JiB1"
      },
      "outputs": [],
      "source": [
        "def blurr_images(arr):\n",
        "    new_arr = []\n",
        "    for i in range(len(arr)):\n",
        "        newimage = arr[i].flatten()\n",
        "        newimage = newimage[permutation]\n",
        "        newimage = newimage.reshape(28,28)\n",
        "        new_arr.append(newimage)\n",
        "    return np.asarray(new_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt-xGS9yJiB1"
      },
      "outputs": [],
      "source": [
        "blurr_train_image = blurr_images(train_image)\n",
        "blurr_test_image = blurr_images(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WlHSQXrJiB1"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    plt.subplot(2,4 , 2*i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_image[i].reshape(28,28))\n",
        "    plt.xlabel(output_mapping[train_label[i]])\n",
        "    plt.subplot(2,4 , 2*i + 2)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(blurr_train_image[i].reshape(28,28))\n",
        "    plt.xlabel(output_mapping[train_label[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx6z3znjJiB1"
      },
      "outputs": [],
      "source": [
        "blurrmodel = models.Sequential()\n",
        "blurrmodel.add(layers.Flatten())\n",
        "blurrmodel.add(layers.Dense(784,activation='relu'))\n",
        "blurrmodel.add(layers.Dense(400,activation='relu'))\n",
        "blurrmodel.add(layers.Dense(300,activation='relu'))\n",
        "blurrmodel.add(layers.Dense(200,activation='relu'))\n",
        "blurrmodel.add(layers.Dense(100,activation=\"relu\"))\n",
        "blurrmodel.add(layers.Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzFqM5ZQJiB1"
      },
      "outputs": [],
      "source": [
        "blurrmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFtgHBjdJiB1"
      },
      "outputs": [],
      "source": [
        "blurrmodel.fit(blurr_train_image, train_label, epochs = 30, batch_size=32, validation_data=(blurr_test_image, test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldMMFfHIJiB2"
      },
      "outputs": [],
      "source": [
        "blurrpredictions = blurrmodel.predict(blurr_test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV2HTRc1JiB2"
      },
      "outputs": [],
      "source": [
        "blurrmodel.evaluate(blurr_test_image, test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92K_YKqaJiB2"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    visualize_pred(blurr_test_image[i], blurrpredictions[i],test_label[i])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}